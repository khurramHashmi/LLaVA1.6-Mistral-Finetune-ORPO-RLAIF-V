from datasets import load_dataset
import os

# Define save paths
train_path = "rlaif-v-train-only"
val_path = "rlaif-v-validation-only"

# âœ… Check if datasets already exist to avoid re-splitting
if os.path.exists(train_path) and os.path.exists(val_path):
    print(f"âœ… Train & Validation splits already exist. Skipping dataset split.")
else:
    print("ğŸ”¹ Loading full dataset...")
    dataset = load_dataset("openbmb/RLAIF-V-Dataset", split="train")

    # âœ… Step 2: Shuffle dataset
    dataset = dataset.shuffle(seed=42)

    # âœ… Step 3: Create 90/10 split
    train_size = int(0.9 * len(dataset))
    train_dataset = dataset.select(range(train_size))  # First 90%
    val_dataset = dataset.select(range(train_size, len(dataset)))  # Last 10%

    # âœ… Step 4: Save both splits
    print(f"âœ… Train Set Size: {len(train_dataset)} | Validation Set Size: {len(val_dataset)}")
    os.makedirs(train_path, exist_ok=True)
    os.makedirs(val_path, exist_ok=True)

    print("ğŸ”¹ Saving train & validation datasets to disk...")
    train_dataset.save_to_disk(train_path)
    val_dataset.save_to_disk(val_path)
    print("âœ… Splits saved successfully!")

print(f"âœ… Train set location: {train_path}")
print(f"âœ… Validation set location: {val_path}")
